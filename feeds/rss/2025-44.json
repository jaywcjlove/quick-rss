[
  {
    "id": "215",
    "url": "https://wangchujiang.com/quick-rss/issue/215.html",
    "title": "Mocolamma: 一款开源的用于管理 Ollama 服务器和模型的多平台应用",
    "content_html": "<p>Mocolamma 是一款为 macOS、iOS、iPadOS 和 visionOS 打造的多平台应用，可连接远程 Ollama 服务器，查看模型详细信息并轻松添加新模型。</p>\n<img alt=\"Mocolamma\" src=\"https://github.com/user-attachments/assets/68f4787b-68eb-47b9-9047-d1e3ad09c8cf\">\n<img alt=\"Mocolamma\" src=\"https://github.com/user-attachments/assets/b0e36936-884f-42b5-a7a6-3eeb7c7b6e4f\">\n<img alt=\"Mocolamma\" src=\"https://github.com/user-attachments/assets/6d647b4f-93c4-4dc8-b480-5e180796de4f\">\n<img alt=\"Mocolamma\" src=\"https://github.com/user-attachments/assets/06733c5e-2182-4c80-92ed-7504a24f1f5d\">\n<p>Mocolamma 这个名字由 “Model + Control + Ollama + Manage” 组合而成，正如名称所示，它是一款以模型管理为核心的开源工具。</p>\n<blockquote>\n<p>请注意：Mocolamma 不包含 Ollama，需要自行运行独立的 Ollama 服务器。</p>\n</blockquote>",
    "summary": "Mocolamma 是一款为 macOS、iOS、iPadOS 和 visionOS 打造的多平台应用，可连接远程 Ollama 服务器，查看模型详细信息并轻松添加新模型。 Mocolamma 这个名字由 “Model + Control + Ollama + Manage” 组合而成，正如名称所示，它是一款以模型管理为核心的开源工具。 > 请注意：Mocolamma 不包含 Ollama，需要自",
    "banner_image": null,
    "date_published": "2025-10-30T18:04:41Z",
    "author": {
      "name": "jaywcjlove",
      "link": "https://avatars.githubusercontent.com/u/1680273?v=4"
    },
    "markdownContent": "Mocolamma 是一款为 macOS、iOS、iPadOS 和 visionOS 打造的多平台应用，可连接远程 Ollama 服务器，查看模型详细信息并轻松添加新模型。\n\n<img alt=\"Mocolamma\" src=\"https://github.com/user-attachments/assets/68f4787b-68eb-47b9-9047-d1e3ad09c8cf\" />\n\n<img alt=\"Mocolamma\" src=\"https://github.com/user-attachments/assets/b0e36936-884f-42b5-a7a6-3eeb7c7b6e4f\" />\n\n<img alt=\"Mocolamma\" src=\"https://github.com/user-attachments/assets/6d647b4f-93c4-4dc8-b480-5e180796de4f\" />\n\n<img alt=\"Mocolamma\" src=\"https://github.com/user-attachments/assets/06733c5e-2182-4c80-92ed-7504a24f1f5d\" />\n\nMocolamma 这个名字由 “Model + Control + Ollama + Manage” 组合而成，正如名称所示，它是一款以模型管理为核心的开源工具。\n\n> 请注意：Mocolamma 不包含 Ollama，需要自行运行独立的 Ollama 服务器。"
  },
  {
    "id": "214",
    "url": "https://wangchujiang.com/quick-rss/issue/214.html",
    "title": "Osaurus：原生 Apple Silicon 本地 LLM 服务器，配 SwiftUI 与 MLX",
    "content_html": "<p>原生、仅支持 Apple Silicon 的本地 LLM 服务器，基于 Apple 的 MLX 构建，充分发挥 M 系列芯片性能。支持 Apple Foundation 模型，提供 SwiftUI 应用和 SwiftNIO 服务器，兼容 OpenAI 和 Ollama 的接口。</p>\n<img alt=\"Osaurus\" src=\"https://github.com/user-attachments/assets/39a10be1-b194-4ac9-a46c-07e5463dc440\">\n<p><a href=\"https://github.com/user-attachments/assets/050fe99e-757a-454c-9f81-658b6bda6ec7\">https://github.com/user-attachments/assets/050fe99e-757a-454c-9f81-658b6bda6ec7</a></p>\n<h2>亮点：</h2>\n<ul>\n<li>原生 MLX 运行时： 为 Apple Silicon 优化，使用 MLX/MLXLLM</li>\n<li>Apple Foundation 模型： 在支持的 macOS 版本上使用系统默认模型（foundation 或 default）；在可用时由 Apple Neural Engine（ANE）加速</li>\n<li>仅支持 Apple Silicon： 专为 M 系列 Mac 设计和测试</li>\n<li>兼容 OpenAI API： /v1/models 和 /v1/chat/completions（支持流式和非流式）</li>\n<li>兼容 Ollama： /chat 接口，支持 NDJSON 流式输出，适配 OllamaKit 和其他 Ollama 客户端</li>\n<li>函数/工具调用： 类 OpenAI 工具 + tool_choice，支持 tool_calls 解析和增量流输出</li>\n<li>快速令牌流： 使用 Server-Sent Events 提供低延迟输出</li>\n<li>应用内聊天覆盖层： 可在可调整大小的玻璃窗口中直接与模型聊天 — 支持流式输出、Markdown、模型选择器和全局快捷键（默认 ⌘;）</li>\n<li>模型管理界面： 浏览、下载和管理来自 mlx-community 的 MLX 模型</li>\n<li>系统资源监控： 实时显示 CPU 和内存使用情况</li>\n<li>自包含： SwiftUI 应用内嵌 SwiftNIO HTTP 服务器</li>\n</ul>\n<p>由 Dinoki Labs (dinoki.ai) 创建 — 完全原生的桌面 AI 助手与伴侣。</p>",
    "summary": "原生、仅支持 Apple Silicon 的本地 LLM 服务器，基于 Apple 的 MLX 构建，充分发挥 M 系列芯片性能。支持 Apple Foundation 模型，提供 SwiftUI 应用和 SwiftNIO 服务器，兼容 OpenAI 和 Ollama 的接口。 https://github.com/user-attachments/assets/050fe99e-757a-454",
    "banner_image": null,
    "date_published": "2025-10-29T02:30:23Z",
    "author": {
      "name": "jaywcjlove",
      "link": "https://avatars.githubusercontent.com/u/1680273?v=4"
    },
    "markdownContent": "原生、仅支持 Apple Silicon 的本地 LLM 服务器，基于 Apple 的 MLX 构建，充分发挥 M 系列芯片性能。支持 Apple Foundation 模型，提供 SwiftUI 应用和 SwiftNIO 服务器，兼容 OpenAI 和 Ollama 的接口。\n\n<img alt=\"Osaurus\" src=\"https://github.com/user-attachments/assets/39a10be1-b194-4ac9-a46c-07e5463dc440\" />\n\nhttps://github.com/user-attachments/assets/050fe99e-757a-454c-9f81-658b6bda6ec7\n\n## 亮点：\n\n- 原生 MLX 运行时： 为 Apple Silicon 优化，使用 MLX/MLXLLM\n- Apple Foundation 模型： 在支持的 macOS 版本上使用系统默认模型（foundation 或 default）；在可用时由 Apple Neural Engine（ANE）加速\n- 仅支持 Apple Silicon： 专为 M 系列 Mac 设计和测试\n- 兼容 OpenAI API： /v1/models 和 /v1/chat/completions（支持流式和非流式）\n- 兼容 Ollama： /chat 接口，支持 NDJSON 流式输出，适配 OllamaKit 和其他 Ollama 客户端\n- 函数/工具调用： 类 OpenAI 工具 + tool_choice，支持 tool_calls 解析和增量流输出\n- 快速令牌流： 使用 Server-Sent Events 提供低延迟输出\n- 应用内聊天覆盖层： 可在可调整大小的玻璃窗口中直接与模型聊天 — 支持流式输出、Markdown、模型选择器和全局快捷键（默认 ⌘;）\n- 模型管理界面： 浏览、下载和管理来自 mlx-community 的 MLX 模型\n- 系统资源监控： 实时显示 CPU 和内存使用情况\n- 自包含： SwiftUI 应用内嵌 SwiftNIO HTTP 服务器\n\n由 Dinoki Labs (dinoki.ai) 创建 — 完全原生的桌面 AI 助手与伴侣。"
  },
  {
    "id": "213",
    "url": "https://wangchujiang.com/quick-rss/issue/213.html",
    "title": "Dropp：开源的跨平台文件投递工具，让你能在 macOS 上拖拽文件到“投递架”，一键同步到云端",
    "content_html": "<p>Dropp 是一款现代化的跨平台文件传输与同步工具，让文件在你的设备之间无缝流动。\n在 macOS 上将文件拖拽至 Dropp 的“投递架”，即可一键同步到云端，随后可在 Android 或其他设备上轻松访问。\n与传统文件传输方式不同，Dropp 提供了一个持久的投递架，让你能快速在多设备间移动文件。</p>\n<p><img src=\"https://github.com/user-attachments/assets/e0177d0d-a504-4fd5-9292-0fb469733f72\" alt=\"Dropp\"></p>\n<p>目前支持 macOS 与 Android，Windows 版本即将推出。</p>\n<h2>主要特性：</h2>\n<ul>\n<li>🔓 完全开源：完整源代码公开于 GitHub，支持社区协作</li>\n<li>☁️ 云端同步：macOS 上传文件后，可在 Android 与其他设备访问</li>\n<li>📦 原生 macOS 投递区：快速、简洁的悬浮面板设计</li>\n<li>📱 原生 Android 应用：随时访问云端文件</li>\n<li>🔐 安全认证：基于 Firebase 的加密会话管理</li>\n<li>⚡ 零配置使用：一次登录，全设备通用</li>\n<li>🎯 持久投递架：文件可保留在架上，随时同步到云端</li>\n</ul>",
    "summary": "Dropp 是一款现代化的跨平台文件传输与同步工具，让文件在你的设备之间无缝流动。 在 macOS 上将文件拖拽至 Dropp 的“投递架”，即可一键同步到云端，随后可在 Android 或其他设备上轻松访问。 与传统文件传输方式不同，Dropp 提供了一个持久的投递架，让你能快速在多设备间移动文件。 目前支持 macOS 与 Android，Windows 版本即将推出。 ## 主要特性： - ",
    "banner_image": "https://github.com/user-attachments/assets/e0177d0d-a504-4fd5-9292-0fb469733f72",
    "date_published": "2025-10-25T06:35:06Z",
    "author": {
      "name": "jaywcjlove",
      "link": "https://avatars.githubusercontent.com/u/1680273?v=4"
    },
    "markdownContent": "Dropp 是一款现代化的跨平台文件传输与同步工具，让文件在你的设备之间无缝流动。\n在 macOS 上将文件拖拽至 Dropp 的“投递架”，即可一键同步到云端，随后可在 Android 或其他设备上轻松访问。\n与传统文件传输方式不同，Dropp 提供了一个持久的投递架，让你能快速在多设备间移动文件。\n\n![Dropp](https://github.com/user-attachments/assets/e0177d0d-a504-4fd5-9292-0fb469733f72)\n\n目前支持 macOS 与 Android，Windows 版本即将推出。\n\n## 主要特性：\n\n- 🔓 完全开源：完整源代码公开于 GitHub，支持社区协作\n- ☁️ 云端同步：macOS 上传文件后，可在 Android 与其他设备访问\n- 📦 原生 macOS 投递区：快速、简洁的悬浮面板设计\n- 📱 原生 Android 应用：随时访问云端文件\n- 🔐 安全认证：基于 Firebase 的加密会话管理\n- ⚡ 零配置使用：一次登录，全设备通用\n- 🎯 持久投递架：文件可保留在架上，随时同步到云端"
  },
  {
    "id": "212",
    "url": "https://wangchujiang.com/quick-rss/issue/212.html",
    "title": "NCE Flow: 开源的新概念英语在线点读工具，新概念英语在线点读，点句即读、连续播放。",
    "content_html": "<p>新概念英语在线点读，点句即读、连续播放，在线体验: <a href=\"https://nce.luzhenhua.cn/\">https://nce.luzhenhua.cn/</a></p>\n<h2>核心功能</h2>\n<ul>\n<li><strong>句子级点读</strong>：点击任意句子开始播放，自动高亮跟随</li>\n<li><strong>多语言视图</strong>：EN / EN+CN / CN 三种显示模式</li>\n<li><strong>播放控制</strong>：倍速调节、连读/点读切换、循环模式、断点续播</li>\n<li><strong>全局快捷键</strong>：空格播放/暂停、方向键导航、音量控制</li>\n<li><strong>学习管理</strong>：课程收藏、学习记录、进度追踪</li>\n<li><strong>现代界面</strong>：Apple 风格、深浅色主题、响应式设计</li>\n<li><strong>零依赖</strong>：纯静态文件，解压即用</li>\n</ul>\n<h2>Docker 一键部署（最简单）</h2>\n<p>只需一条命令，无需下载代码：</p>\n<pre class=\"language-bash\"><code class=\"language-bash code-highlight\"><span class=\"code-line line-number\" line=\"1\"><span class=\"token function\">docker</span> run <span class=\"token parameter variable\">-d</span> <span class=\"token parameter variable\">-p</span> <span class=\"token number\">8080</span>:80 <span class=\"token parameter variable\">--name</span> nce-flow <span class=\"token parameter variable\">--restart</span> unless-stopped luzhenhua/nce-flow:latest\n</span></code></pre>\n<p>然后访问 <code>http://localhost:8080</code> 即可！</p>\n<p><strong>自定义端口：</strong></p>\n<pre class=\"language-bash\"><code class=\"language-bash code-highlight\"><span class=\"code-line line-number\" line=\"1\"><span class=\"token function\">docker</span> run <span class=\"token parameter variable\">-d</span> <span class=\"token parameter variable\">-p</span> <span class=\"token number\">3000</span>:80 <span class=\"token parameter variable\">--name</span> nce-flow <span class=\"token parameter variable\">--restart</span> unless-stopped luzhenhua/nce-flow:latest\n</span></code></pre>",
    "summary": "新概念英语在线点读，点句即读、连续播放，在线体验: https://nce.luzhenhua.cn/ ## 核心功能 - **句子级点读**：点击任意句子开始播放，自动高亮跟随 - **多语言视图**：EN / EN+CN / CN 三种显示模式 - **播放控制**：倍速调节、连读/点读切换、循环模式、断点续播 - **全局快捷键**：空格播放/暂停、方向键导航、音量控制 - **学习管理**",
    "banner_image": null,
    "date_published": "2025-10-25T04:20:52Z",
    "author": {
      "name": "jaywcjlove",
      "link": "https://avatars.githubusercontent.com/u/1680273?v=4"
    },
    "markdownContent": "新概念英语在线点读，点句即读、连续播放，在线体验: https://nce.luzhenhua.cn/ \n\n## 核心功能\n\n- **句子级点读**：点击任意句子开始播放，自动高亮跟随\n- **多语言视图**：EN / EN+CN / CN 三种显示模式\n- **播放控制**：倍速调节、连读/点读切换、循环模式、断点续播\n- **全局快捷键**：空格播放/暂停、方向键导航、音量控制\n- **学习管理**：课程收藏、学习记录、进度追踪\n- **现代界面**：Apple 风格、深浅色主题、响应式设计\n- **零依赖**：纯静态文件，解压即用\n\n## Docker 一键部署（最简单）\n\n只需一条命令，无需下载代码：\n\n```bash\ndocker run -d -p 8080:80 --name nce-flow --restart unless-stopped luzhenhua/nce-flow:latest\n```\n\n然后访问 `http://localhost:8080` 即可！\n\n**自定义端口：**\n```bash\ndocker run -d -p 3000:80 --name nce-flow --restart unless-stopped luzhenhua/nce-flow:latest\n```"
  }
]
